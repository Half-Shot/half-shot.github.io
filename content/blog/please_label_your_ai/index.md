+++
title = "Please label your AI"
description = "Your LLMs aren't oiling the gears, they are filling them with mud"
date = 2026-01-08
[taxonomies]
categories = ["llms", "AI", "open source"]
+++

Halfy blog posts are like buses, you wait half a year for one and then two come along at once.
Anyway, this one is cooked up fresh from the mind of someone who's just gone back to work.

## Intro

When I was 5 or 6, I loved computers. This was the early 2000s when everyone had a big green
hill and blue skies on their recently flattened monitors, and computers could now do everything!

I used to make little websites that did horrible flashy effects, make animations in Macromedia Flash
and play Worms Armageddon with my brothers. Grandfather Halfy was not so keen. He was a proud Luddite
who at that age left me with the impression he was burning down warehouses full of computers on his weekends.
I suspect that was no more true than the gold he hid under his floorboards, but I do remember the most advanced
bit of tech in the house was a DVD recorder. Otherwise, nothing. And it fascinated me.

Growing up I remember that I did not want to be that person. I **loved** computers because I could do so much
and later would make friends through computers, get paid through them and even fall in love through
meeting people on those connections. The idea of burning down those would burn down my life's ambitions.

I'm a strong believer in keeping up with the times and adapting to change. It's not *me* to dig my feet into the
ground for the sake of it, but try as I might I cannot love AI. LLMs appear constantly around what I do, and they
never spark that joy. I've now connected with my late grandfather's words about wanting to burn them down.

With the ever increasing usage of ChatGTP/Claude and the many many other models and tools out there, I think
something needs to be said.


## This does not spark joy

And I think the problem I fundamentally have with AI on a personal level is that computers are to me a way to
express my creativity. I've gotten hired off that creative ability to reason around a problem, and I've given
much fulfilment to my life through making music, drawing, photo-shopping or building random janky websites as
a meme.

I can't see the joy in filling a prompt and getting some output. That's just hiring someone to experience the
joy for you. The computer can't feel joy, so nobody wins. What a result.

And aside from the occasional bit of faux-enjoyment where a Reddit post turns out to be fake, I'm managing to
dodge AI. So far, I'm lucky to work for a place where AI is not enforced like some work places and my friends
and family largely do not buy into the hype. And I have a hackerspace to camp in if things get too bad.

In truth, I'm hoping it eventually fades the same way blockchain, NFTs and the other monsters did.

## But I'm angry

And right now I'm angry in the same way my Science teacher graded me down for not labelling my axis on a graph;
**PEOPLE ARE NOT LABELLING THEIR SHIT**. 

I get it, you like AI. That's cool for you, and I don't want to burn down your ambitions. But for sake of our
collective sanity, stop burning the goodwill of everyone else. When you generate some content, tell people it
was generated by a AI.

I'm reading Reddit posts pretending to be humans, I'm seeing YouTube videos so obviously AI that I can't filter
out. I'm reviewing code from community members written by AI that will *never* work.

On the software side, I'm noticing a much more worrying trend where AI has now allowed contributors to pick off
issues they don't like, generate some half baked code, and then expect the maintainers to form it into a fix. I want
to believe these people think they are helping.

In the before times we would see the occasional Pull Request come in for one of our projects and spend time
reviewing it. It might be bad, but there was a genuine appreciation that someone had taken the time to download
our project and attempt to learn how it works. I remember being that person a long time ago and getting a lot
of training from maintainers on how to write good code, and how to be a team player. I want to believe over my
maintainership years, I may have helped other people too. 

But with the advent LLMs, it's been impossible not to equate some of the bad code with someone using a LLM. I then
have to make the choice whether to even engage at all, potentially wasting my time trying to train a machine
more than a person.

So let me be clear to people out there using LLMs on projects they are not familiar with. You might think you are
helping, oiling the gears of software that you know and love and trying to make them better. You are not doing this
**you are filling the gears with mud.**.

## So to be clear

I am probably never going to get on with AI, however good it gets. I enjoy the learning curve of a craft, I
get a lot out of fixing bugs with my human brain and I will play music and sing in terrible quality til the day
I depart this Earth. I am not interested in the absolute quality or perceived productiveness, I get a thrill from
just the experience.

But I don't want to trample on the fun people have with generating content, if that's their bag then they
may have their cake. All that I ask is that you let us Luddites know that you consulted an AI, roughly
how much of that work is your own, and give us the *choice* to decide whether we want to engage with it.